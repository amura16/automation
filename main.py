# -*- coding: utf-8 -*-
"""reddit_scrap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IaCbCQac-sJYdo6oJkXsivUUA_k8cpzz
"""

import praw
import asyncio
import pandas as pd
from pymongo import MongoClient

def reddit_scrap():

    client_id = "RiaZSGXrAfcvd-nBZR0fiQ"
    client_secret = "Ma5FAfGIpS4dr56crDKB-s14pClZVg"
    user_agent = "python:scrap:v1.0 (by /u/No-Flan6855)"
    username = "No-Flan6855"
    password = "roddytanjakaReddit#"

    reddit = praw.Reddit(
        client_id=client_id,
        client_secret=client_secret,
        user_agent=user_agent,
        username=username,
        password=password
    )

    print(reddit.user.me())



    def get_comments(submission):
        comments = []
        try:
            submission.comments.replace_more(limit=0)
            for comment in submission.comments:
                replies = []
                if len(comment.replies) > 0:
                    comment.replies.replace_more(limit=0)
                    for reply in comment.replies:
                        replies.append({
                            "id": reply.id,
                            "author": str(reply.author), # Convert Redditor object to string
                            "created_utc": reply.created_utc,
                            "score": reply.score,
                            "body": reply.body
                        })

                    replies = sorted(replies, key=lambda x: x["score"], reverse=True)[:5]
                    comments.append({
                        "id": comment.id,
                        "author": str(comment.author), # Convert Redditor object to string
                        "created_utc": comment.created_utc,
                        "score": comment.score,
                        "body": comment.body,
                        "replies": replies
                    })

            comments = sorted(comments, key=lambda x: x["score"], reverse=True)[: (20 if len(comments)>20 else len(comments))]
            return comments

        except:
            return []


    def get_post(sort_type, submission, get_comments):
        return {
            "id": submission.id,
            "title": submission.title,
            "text": submission.selftext,
            "author": str(submission.author), # Convert Redditor object to string
            "score": submission.score,
            "created_utc": submission.created_utc,
            "num_comments": submission.num_comments,
            "subreddit": str(submission.subreddit), # Convert Subreddit object to string
            "sort_type": sort_type,
            "comments": get_comments(submission)
        }

    # get hot reddit posts
    subreddit = reddit.subreddit("all")
    hot_sub_posts = []
    hot_subreddits = set()
    for submission in subreddit.hot(limit=20):
        if len(hot_subreddits) < 5:
            hot_subreddits.add(str(submission.subreddit))
        else:
            break

    for subreddit_name in hot_subreddits:
        subreddit = reddit.subreddit(subreddit_name)
        submissions_list = []
        for submission in subreddit.hot(limit=5):
            post_data = get_post(sort_type="hot", submission=submission, get_comments=get_comments)
            submissions_list.append(post_data)
        for submission in subreddit.top(limit=5):
            post_data = get_post(sort_type="top", submission=submission, get_comments=get_comments)
            submissions_list.append(post_data)
        hot_sub_posts.extend(submissions_list)


    print(f"Scraped {len(hot_sub_posts)} hot subreddit posts.")

    # get top reddit posts
    subreddit = reddit.subreddit("all")
    top_sub_posts = []
    top_subreddits = set()
    for submission in subreddit.top(limit=20):
        if len(top_subreddits) < 5:
            top_subreddits.add(str(submission.subreddit))
        else:
            break

    for subreddit_name in top_subreddits:
        subreddit = reddit.subreddit(subreddit_name)
        submissions_list = []
        for submission in subreddit.hot(limit=5):
            post_data = get_post(sort_type="hot", submission=submission, get_comments=get_comments)
            submissions_list.append(post_data)
        for submission in subreddit.top(limit=5):
            post_data = get_post(sort_type="top", submission=submission, get_comments=get_comments)
            submissions_list.append(post_data)
        top_sub_posts.extend(submissions_list)

    print(f"Scraped {len(top_sub_posts)} top posts.")

    # combine all posts
    all_posts_data = hot_sub_posts + top_sub_posts
    print(f"Total French posts scraped: {len(all_posts_data)}")

    # connection to Mongodb
    client = MongoClient("mongodb://rdadmin:Apxve39YlrOEWG6@57.129.18.234:27017/redditdatascrape?authSource=redditdatascrape")
    db = client["redditdatascrape"]
    collection = db["reddit_data"]

    if all_posts_data:
        collection.insert_many(all_posts_data)
        print(f"Successfully inserted {len(all_posts_data)} posts into MongoDB.")
    else:
        print("No posts to insert.")